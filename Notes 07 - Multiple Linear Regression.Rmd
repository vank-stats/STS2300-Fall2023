---
title: "Notes 07 - Multiple Linear Regression (MLR)"
author: "STS 2300 (Fall 2023) - Dr. VanKrevelen"
date: 'Updated: 09/19/2023'
output:
  word_document:
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
masks <- read.csv("https://raw.githubusercontent.com/vank-stats/STS2720-Fall2022/main/masks_covid.csv")
```

---

# Reading for Notes 07

Read [Chapter 6](https://moderndive.com/6-multiple-regression.html) of the Modern Dive textbook. You can skip Section 6.1 and 6.3.1 since we won't cover categorical explanatory variables in this class. (Note: You can take STS 2320 to learn more about many different forms of regression including ones using categorical explanatory variables. Section 6.1 is also similar to something you might see in STS 3250.)

---

# Learning Goals for Notes 07

* Be able to use R to generate multiple linear regression equations and to make predictions with them.
* Understand how to interpret the intercept and slope of a multiple linear regression equation in context.
* Be able to appropriately use backward selection to choose a multiple linear regression model.
* Be able to determine and interpret the coefficient of determination ($R^2$) and understand its use and limitations in multiple linear regression.

---

---

I'll be using the following packages in this set of notes, so I'll load them before I get started.

```{r, message = FALSE}
library(ggplot2)
library(dplyr)
library(patchwork)
library(Lock5Data)
```

---

# An example: Predicting Car Mileage

The R package `Lock5Data` (from another statistics textbook) has a dataset called `Cars2015`. I'm going to read it into R and call it `cars`. The dataset consists of 24 variables recorded for 110 car models from 2015. For simplicity, I'm going to focus on how four of the variables might help me predict the highway mileage for a car from 2015.

```{r}
cars <- Cars2015 %>%
  select(HwyMPG, Length, Height, Acc060, Weight)
```

Below I've used `patchwork` to see how each of the four possible explanatory variables are related to `HwyMPG` in the data.

```{r}
g <- ggplot(cars, aes(y = HwyMPG))

g1 <- g + geom_point(aes(x = Length)) + theme_classic()
g2 <- g + geom_point(aes(x = Height)) + theme_classic()
g3 <- g + geom_point(aes(x = Acc060)) + theme_classic()
g4 <- g + geom_point(aes(x = Weight)) + theme_classic()

(g1 + g2) / (g3 + g4) 
```

**Practice**: Which variables seem to have a linear relationship with `HwyMPG`? Which have the strongest relationship?

**Answer: **

<br>

In simple linear regression (SLR), we used *one* quantitative explanatory variable to help us understand our quantitative response variable. With multiple linear regression (MLR) we can use we use *two or more* explanatory variables to help us understand our quantitative response variable.


---


# The Multiple Linear Regression (MLR) Model

Recall that in simple linear regression, we wrote the equation for the "true model" as:

$$y = \beta_0 + \beta_1 x$$

and we wanted to estimate the "true y-intercept" ($\beta_0$) and the "true slope" ($\beta_1$). 

We can expand on this idea for multiple linear regression by essentially adding new "slopes" for *each* of our explanatory variables. This gets harder to visualize on a single graph, but the idea is the same. Since our example above had four explanatory variables, we could write the equation for the true model we want to estimate as:

$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_x + \beta_3 x_3 + \beta_4 x_4$$

Each of the $\beta_i$ values is an unknown parameter. However, we can make estimates for each of them and calculate an estimated model:

$$\hat{y} = b_0 + b_1 x_1 + b_2 x_2 + b_3 x_3 + b_4 x_4$$

In this equation, $\hat{y}$ would be our predicted highway miles per gallon, $x_1$ through $x_4$ would be the values for our four explanatory variables, and $b_1$ through $b_4$ would be the estimated slopes associated with each variable.



## Using R to get an estimated line

Suppose I have $k$ explanatory variables. To get my estimated line using R, my code would look like

```{r, eval = FALSE}
lm(response ~ explanatory1 + explanatory2 + ... + explanatoryk, data = dataset)
```

Let's try that for the car example.

```{r}
lm(HwyMPG ~ Length + Height + Acc060 + Weight, data = cars)
```

Notice how in the output I have a number for the intercept and then another number associated with each explanatory variable in my model. Those are my estimated slopes. I could write my equation as:

$$\widehat{HwyMPG} = 34.01 + .0745*Length - 0.1728*Height + 1.6328*Acc060 - 0.0045*Weight$$

<br>

**Question:** Do these coefficients match the direction we saw in the scatterplots above? If not, why do you think that might be?

**Answer:**

<br>


## Predictions with MLR Models

The process for making predictions in a multiple linear regression model is similar to a simple linear regression model, but I'll need to plug something in for each of my explanatory variables.

The Nissan Pathfinder in 2015 had a length of 192 inches, a height of 72 inches, an acceleration from 0 to 60 mph of 7.7 seconds, and a weight of 4505 pounds. Suppose that we didn't have data on the highway miles per gallon for this car. I could use my model to make a prediction:

$$\widehat{HwyMPG} = 34.01 + .074*192 - 0.173*72 + 1.633*7.7 - 0.004*4505$$

To have R do this calculation for me, my code would be:

```{r}
cars.lm <- lm(HwyMPG ~ Length + Height + Acc060 + Weight, data = cars)
predict(cars.lm, newdata = data.frame(Length = 192, 
                                      Height = 72, 
                                      Acc060 = 7.7,
                                      Weight = 4505))
```

My prediction is that the car would have a highway mileage of 24.66 miles per gallon. The actual value in the dataset was 25 miles per gallon, so it looks like this would have been a good prediction!

Recall that the residual is the distance between the actual value and your prediction. My residual for the Nissan Pathfinder is $Residual = y - \hat{y} = 25 - 24.66 = 0.34$, which is also telling me that my observed mileage was just a little bit above my predicted mileage for this car.

One way to decide how well our model was working would be to compare the predicted mileages to the actual mileages.

```{r, out.width = "60%", fig.align = "center"}
cars$predictedHwyMPG <- predict(cars.lm)
ggplot(cars) +
  geom_point(aes(x = HwyMPG, y = predictedHwyMPG)) +
  geom_abline(slope = 1) +
  labs(title = "Actual vs. Predicted MPG", x = "Actual Highway MPG", 
       y = "Predicted Highway MPG")
```

**Question**: What do you notice? What might we wonder? (Hint: Consider how good our predictions are for different values of the response)

**Answer:**

<br>



---



# Interpreting MLR Models

## The estimated y-intercept, $b_0$

Recall that in a simple linear regression model, we interpreted $b_0$ as the predicted value of the response variable when the explanatory variable was 0. For multiple linear regression, the only thing we need to change is that $b_0$ is the predicted value of the response variable when *all of the explanatory variables* are 0.

Thus, for the example above where $b_0 = 34.01$, we could interpret it by saying:

> The predicted highway mileage of a car model is 34.01 miles per gallon if that car has a length, height, weight, and acceleration speed (from 0 to 60 mph) of 0.


**Question:** Does this prediction seem like an extrapolation? Why or why not?

**Answer:**

<br>



## The estimated slope(s)

In a simple linear regression model we had one slope, $b_1$, and we interpreted it as the predicted change in our response variable if our explanatory variable went up by one unit. In our multiple linear regression model, we have more than one explanatory variable, so we need to make an addition to our interpretation.


> **General interpretation of MLR slope(s)**: The *predicted* response increases/decreases (based on + or - sign) by the absolute value of $b_i$ for every one unit increase in that explanatory variable *assuming all other explanatory variables are held constant*.


In other words, we want to make sure we're talking about *only* changing that variable. Sometimes this can lead to interpretations seeming a bit odd. Here is an example using the weight variable.


> Interpretation of weight slope: The predicted highway mileage decreases by 0.004
miles per gallon for each additional pound a car weighs (assuming the length, height, and acceleration from 0 to 60 mph are held constant for the car).


This make sense that heavier cars would probably get worse gas mileage since they require more energy to move.

<br>

**Practice**: Try writing an interpretation for the slope for the height variable (-0.173).

**Interpretation:**

<br>


**Practice**: Try writing an interpretation for the slope for the length variable (0.074).

**Interpretation:**

<br>


**Question**: Do either of your interpretations seem a bit counter intuitive (or to not match our graphs from before)? Why do you think that is?

**Answer:**

<br>



---

# Using backwards selection to choose variables for an MLR model

Recall that the $R^2$ value tells us the proportion of the variability in our response variable that can be explained by our explanatory variables. It might seem like we should choose the model that has the highest $R^2$ value, but doing this would mean we always add as many variables as possible to our model because adding a new variable can never lead to us explaining *less* of the variability. However, a larger model is harder to interpret and may lead to us "over-fitting" our data.

An alternative approach is called **backward selection** (or backward elimination). With this approach, we put all of our explanatory variables in our model and then remove them one at a time until we have a model where all of the explanatory variables have estimated slopes with statistically significant p-values (according to a pre-chosen cutoff).

(**Note:** The **adjusted $R^2$** value partially addresses this by accounting for the number of variables. Some people may also use this to choose when to stop removing variables from their model.)


Let's add a few variables to our car example from above.

```{r}
Cars2015 %>%
  lm(HwyMPG ~ Length + Width + Height + Weight + Acc030 + Acc060, data = .) %>%
  summary()
```

We can see that several of our variables do **not** have statistically significant p-values (including some that did in our smaller model earlier). The largest p-value (0.5110) belongs to the `Acc030` variable. Try removing this variable and refitting the model. 

```{r}
Cars2015 %>%
  lm(HwyMPG ~ Length + Width + Height + Weight + Acc060, data = .) %>%
  summary()
```

Notice how now `Acc060` has a **much smaller** p-value.

**Question:** Why did the p-value associated with `Acc060` change so much?

**Answer:**


**Question:** Which variable should we try removing next? Why?

**Answer:**


**Practice:** Try removing that variable. Should we stop at this model or remove other variable(s)?

**Answer:**



---



# Considering data context

**Question**: This data was specifically from 2015 car models. Would it make sense to use it on 2021 cars? 

**Answer**: I'm not sure... It probably depends on how different they are. Are different materials being used now? Have driving conditions or habits changed? Etc.

<br>

Regardless, we should always be careful when we use data from one population to make predictions in another population. This is a common issue in a lot of artificial intelligence and machine learning (aka fancy black box statistics applications) problems these days. Some examples include [facial recognition software](https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms) not recognizing people with dark skin, [Amazon downgrading female job applicants](https://www.aclu.org/blog/womens-rights/womens-rights-workplace/why-amazons-automated-hiring-tool-discriminated-against) because their past hires were mostly male, and much more. 

In many of these cases, people using the models didn't think they were being biased. They may have even avoided putting factors like race or sex into their model thinking that meant they wouldn't be using those factors to make decisions. However, our society is complex and all kinds of variables are related to other variables (like we saw just in a much less consequential example above). This means we really need to be careful about how we interpret and use the models that we create with data.


Other resources if this interests you:

- Book: Weapons of Math Destruction ([NPR Interview](https://www.npr.org/2016/09/12/493654950/weapons-of-math-destruction-outlines-dangers-of-relying-on-data-analytics)) 
- Book: Data Feminism ([free online version](https://data-feminism.mitpress.mit.edu/))
- Netflix Documentary: Coded Bias ([website](https://www.codedbias.com/))



---



# Revisiting the Learning Goals for Notes 07

* Be able to use R to generate multiple linear regression equations and to make predictions with them.
* Understand how to interpret the intercept and slope of a multiple linear regression equation in context.
* Be able to appropriately use backward selection to choose a multiple linear regression model.
* Be able to determine and interpret the coefficient of determination ($R^2$) and understand its use and limitations in multiple linear regression.